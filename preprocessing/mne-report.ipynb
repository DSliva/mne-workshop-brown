{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quality assurance with MNE report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's say we want to analyze 100 subjects.\n",
    "\n",
    "How do we do quality assurancy in a scalable manner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNE report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from mne.report import Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A report contains:\n",
    "    * Figures\n",
    "    * Images\n",
    "    * Custom HTML\n",
    "    * Sliders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let us generate some figures for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "data_path = sample.data_path()\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "\n",
    "#preload=true -> load data from disk to memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's pretend this data came from 3 different subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-01_raw.fif\n",
      "Closing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-01_raw.fif [done]\n",
      "Overwriting existing file.\n",
      "Writing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-02_raw.fif\n",
      "Closing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-02_raw.fif [done]\n",
      "Overwriting existing file.\n",
      "Writing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-03_raw.fif\n",
      "Closing /home/jovyan/mne_data/MNE-sample-data/MEG/sample/sub-03_raw.fif [done]\n"
     ]
    }
   ],
   "source": [
    "#copy so don't modify raw instance\n",
    "\n",
    "raw1 = raw.copy().crop(0, 20)\n",
    "raw2 = raw.copy().crop(20, 40)\n",
    "raw3 = raw.copy().crop(40, 60)\n",
    "\n",
    "raw1.save(data_path + '/MEG/sample/sub-01_raw.fif', overwrite=True)\n",
    "raw2.save(data_path + '/MEG/sample/sub-02_raw.fif', overwrite=True)\n",
    "raw3.save(data_path + '/MEG/sample/sub-03_raw.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can have a function to go from raw to evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "event_id = {'Auditory/Left': 3, 'Auditory/Right': 4}\n",
    "\n",
    "# raw to evoked without preproc\n",
    "\n",
    "def raw_to_evoked(raw_fname, tmin=-0.1, tmax=0.5):\n",
    "    \n",
    "    raw = mne.io.read_raw_fif(data_path + '/MEG/sample/' + raw_fname, preload=True)\n",
    "    fig1 = raw.plot();\n",
    "    raw.filter(0, 40.)\n",
    "    \n",
    "    events = mne.find_events(raw, stim_channel='STI 014')\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax)\n",
    "    fig2 = epochs.plot();\n",
    "    \n",
    "    evoked_l = epochs['Left'].average();\n",
    "    fig3 = evoked_l.plot_topomap()\n",
    "    fig4 = evoked_l.plot();\n",
    "    \n",
    "    # returns 4 figure handles; get list of figs\n",
    "    return [fig1, fig2, fig3, fig4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can get all the figure handles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "figs = raw_to_evoked('sub-01_raw.fif')\n",
    "\n",
    "#capture captures image without changing output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now comes the actual report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rep = Report()\n",
    "#list of figures\n",
    "#figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#give each fig caption\n",
    "captions = ['Raw', 'Epochs', 'Topomap', 'Butterfly']\n",
    "rep.add_figs_to_section(figs, captions=captions)\n",
    "rep.save('report_raw_to_evoked.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The report can be found [here](report_raw_to_evoked.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can go even more fancy. Let's try to process all the three subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "rep = Report()\n",
    "for idx, r in enumerate(['sub-01_raw.fif', 'sub-02_raw.fif', 'sub-03_raw.fif']):\n",
    "    figs = raw_to_evoked(r)\n",
    "    rep.add_figs_to_section(figs, captions=captions, section='Subject %02d' % idx)\n",
    "rep.save('report_raw_to_evoked.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There are tabs for each subject!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Parallel processing\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def raw_to_evoked(raw_fname, tmin=-0.1, tmax=0.5):\n",
    "    raw = mne.io.read_raw_fif(data_path + '/MEG/sample/' + raw_fname, preload=True)\n",
    "    raw.filter(0, 40.)\n",
    "    events = mne.find_events(raw, stim_channel='STI 014')\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax)\n",
    "    evoked_l = epochs['Left'].average();\n",
    "\n",
    "from mne.parallel import parallel_func\n",
    "\n",
    "#iterate over filenames to run script in parallel\n",
    "fnames = ['sub-01_raw.fif', 'sub-02_raw.fif', 'sub-03_raw.fif']\n",
    "parallel, myfunc, _ = parallel_func(raw_to_evoked, n_jobs=3)\n",
    "parallel(myfunc(fname) for fname in fnames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "BEM sliders\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What else can you do? You can inspect quality of the BEM with sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subjects_dir = data_path + '/subjects'\n",
    "\n",
    "rep = Report()\n",
    "rep.add_bem_to_section(subject='sample', subjects_dir=subjects_dir, decim=36)\n",
    "rep.save('report_bem.html')\n",
    "\n",
    "#inspect whether freesurfer segmentation looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Check out the report [here](report_bem.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Custom HTML\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can even add custom htmls. For example, we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<table class=\"table table-hover\">\n",
    "   <tr>\n",
    "       <th>Meas time range</th>\n",
    "       <th>Sampling freq</th>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td> %0.2f to %0.2f </td>\n",
    "       <td> %0.2f </td>\n",
    "   </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "#see 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rep.add_htmls_to_section(html % (raw.times[0], raw.times[-1], raw.info['sfreq']), captions='Info table')\n",
    "rep.save('report_bem.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is the [report](report_bem.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Custom sliders\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And we can make our own sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fname = data_path + '/MEG/sample/sample_audvis-ave.fif'\n",
    "evoked = mne.read_evokeds(fname, condition='Left Auditory',\n",
    "                          baseline=(None, 0), verbose=False)\n",
    "\n",
    "rep = Report()\n",
    "figs = list()\n",
    "times = evoked.times[::4]\n",
    "\n",
    "#add fig handles to report\n",
    "for time in times:\n",
    "    figs.append(evoked.plot_topomap(time, vmin=-300, vmax=300,\n",
    "                                    res=100, show=False))\n",
    "    plt.close(figs[-1])\n",
    "rep.add_slider_to_section(figs, times, 'Evoked Response')\n",
    "rep.save('report_slider.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about quality assurance, check out [this paper](https://www.biorxiv.org/content/biorxiv/early/2017/12/28/240044.full.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exercise\n",
    "--------\n",
    "\n",
    "1) Can you think of creative ways to use the report for your own analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<details>\n",
    "<summary>\n",
    "Here are some ideas:<br/><br/>\n",
    "\n",
    "</summary>\n",
    "- sections with subject names instead of preprocessing step<br/>\n",
    "- custom html/javascript to get quality labels<br/>\n",
    "- sliders to browse through the raw data<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
